{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition Using (K-Nearest Neighbor) KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from skimage import exposure\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Original MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "# load the original MNIST digits dataset\n",
    "train_data = pd.read_csv('./Dataset/train.csv', header=None)\n",
    "train_labels = pd.read_csv('./Dataset/train_labels.csv', header=None)\n",
    "\n",
    "# check data shape\n",
    "print(train_data.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the dataset for training, testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and testing split,\n",
    "# 75% for training and 25% for testing\n",
    "X = train_data.copy()\n",
    "y = train_labels.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42)\n",
    "\n",
    "# normalize the dataset\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# take 10% of the training data and use that for validation\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_train, y_train, test_size=0.10, random_state=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (40500, 784)\n",
      "y_train shape: (40500, 1)\n",
      "X_validate shape: (4500, 784)\n",
      "y_validate shape: (4500, 1)\n",
      "X_test shape: (15000, 784)\n",
      "y_test shape: (15000, 1)\n"
     ]
    }
   ],
   "source": [
    "# checking the splits\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_validate shape:', X_validate.shape)\n",
    "print('y_validate shape:', y_validate.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining the best value of 'k' as it is a hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=96.87%\n",
      "k=2, accuracy=96.51%\n",
      "k=3, accuracy=97.02%\n",
      "k=4, accuracy=96.76%\n",
      "k=5, accuracy=97.02%\n",
      "k=6, accuracy=96.62%\n",
      "k=7, accuracy=96.71%\n",
      "\n",
      "k=3 achieved highest accuracy of 97.02% on validation data\n"
     ]
    }
   ],
   "source": [
    "# list of accuracies for each value of k\n",
    "kVals = range(1, 8, 1)\n",
    "accuracies = []\n",
    "\n",
    "# loop over kVals\n",
    "for k in kVals:\n",
    "# train the classifier with the current value of `k`\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "# evaluate the model and print the accuracies list\n",
    "    score = model.score(X_validate, y_validate)\n",
    "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    accuracies.append(score)\n",
    "\n",
    "# k with largest accuracy will be chosen for final training\n",
    "# np.argmax returns the indices of the maximum values along an axis\n",
    "i = np.argmax(accuracies)\n",
    "\n",
    "print(\"\\nk=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i], accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Evaluating the model using the best value of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9698 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now that I know the best value of k, re-train the classifier\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "\n",
    "# train the model again\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Predict labels for the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_true=y_test.values.ravel(), y_pred=predictions), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1495\n",
      "           1       0.96      0.99      0.98      1649\n",
      "           2       0.97      0.96      0.97      1471\n",
      "           3       0.97      0.96      0.97      1518\n",
      "           4       0.97      0.97      0.97      1443\n",
      "           5       0.96      0.96      0.96      1383\n",
      "           6       0.98      0.99      0.98      1482\n",
      "           7       0.97      0.98      0.97      1635\n",
      "           8       0.99      0.93      0.96      1445\n",
      "           9       0.96      0.96      0.96      1479\n",
      "\n",
      "    accuracy                           0.97     15000\n",
      "   macro avg       0.97      0.97      0.97     15000\n",
      "weighted avg       0.97      0.97      0.97     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of model for each of the digits\n",
    "print(\"Evaluating on test data: \")\n",
    "print(classification_report(y_test.values.ravel(), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['digit-classifier_knn.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dumping the trained model for later use.\n",
    "joblib.dump(model, 'digit-classifier_knn.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the final model on an unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# load the originial MNIST test data set\n",
    "test_data = pd.read_csv('./Dataset/test.csv', header=None)\n",
    "test_labels = pd.read_csv('./Dataset/test_labels.csv', header=None)\n",
    "\n",
    "# normalize test data\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "# check data shape\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9679 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the trained classifier\n",
    "model = joblib.load(\"digit-classifier_knn.joblib\")\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# accuracy\n",
    "print(\"accuracy:\", metrics.accuracy_score(y_true=test_labels.values.ravel(), y_pred=predictions), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.95      1.00      0.98      1135\n",
      "           2       0.98      0.96      0.97      1032\n",
      "           3       0.96      0.97      0.96      1010\n",
      "           4       0.97      0.97      0.97       982\n",
      "           5       0.96      0.97      0.96       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.99      0.93      0.96       974\n",
      "           9       0.96      0.95      0.95      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of model for each of the digits\n",
    "print(\"Evaluating on test data: \")\n",
    "print(classification_report(test_labels.values.ravel(), predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the final model for kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# read kaggle test data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# normalize test data\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the trained model and testing it for kaggle submission\n",
    "model = joblib.load('digit-classifier_knn.joblib')\n",
    "\n",
    "# make predictions\n",
    "y_predict = model.predict(test_data)\n",
    "\n",
    "# preparing data for kaggle submission\n",
    "test_ids = []\n",
    "pred_labels = []\n",
    "\n",
    "for k in range(len(y_predict)):\n",
    "    test_ids.append(k+1)\n",
    "    \n",
    "for k in range(len(y_predict)):\n",
    "    pred_labels.append(y_predict[k])\n",
    "    \n",
    "df = pd.DataFrame(list(zip(test_ids,pred_labels)),\n",
    "                 columns =['ImageId', 'Label'])\n",
    "\n",
    "# create submission file\n",
    "df.to_csv('submission_knn.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
